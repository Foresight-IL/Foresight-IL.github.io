<!DOCTYPE html>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/mml-chtml.js">
</script>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta property="og:title" content="Latent World Models Enhance Imitation Learning with Foresight">
  <meta property="og:description" content="Latent World Models Enhance Imitation Learning with Foresight">
  <meta property="og:type" content="website">
  <meta property="og:site_name" content="Latent World Models Enhance Imitation Learning with Foresight">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Latent World Models Enhance Imitation Learning with Foresight">
  <meta name="twitter:description" content="Latent World Models Enhance Imitation Learning with Foresight">
  <meta name="twitter:image" content="./mfiles/figs/intro.png" />
  <link rel="shortcut icon" href="mfiles/favicon.png">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css">
  <link rel="stylesheet" href="css/simple-grid.css">
  <title>Latent World Models Enhance Imitation Learning with Foresight</title>
</head>

<body>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js"
    integrity="sha384-OERcA2EqjJCMA+/3y+gxIOqMEjwtxJY7qPCqsdltbNJuaOe923+mo//f6V8Qbsw3"
    crossorigin="anonymous"></script>
  <div class="jumbotron">
    <div class="container">
      <div class="row mt-5">
        <div class="col-12 center mb-3">
          <h1 style="font-size: 2.9em;">
            Latent World Models Enhance Imitation Learning with Foresight
          </h1>
        </div>

        <div class="col-3 hidden-sm"></div>
      </div>

      <div class="row mt-3">
        <div class="col-12 center img">
          <img class="center" src="./mfiles/figs/intro.png" style="width:100%; height:auto; overflow:visible;"></img>
        </div>
      </div>

      <!--Abstract-->
      <div class="row mt-3">
        <div class="col-12">
          <h2 class="center m-bottom">Abstract</h2>
          <p>
            Imitation learning (IL) has shown to be a powerful framework for acquiring robotic manipulation skills from
            demonstrations. However, standard approaches fall short in long-horizon or unseen scenarios due to
            compounding errors and a lack of goal-directed reasoning. Crucially, IL does not equip agents with the
            ability to predict and evaluate future outcomes—a capability essential for robust, generalizable behavior.
            Recent advances in world modeling suggest that such predictive capabilities can be captured in task-agnostic
            world models.
          </p>
          <p>
            We propose <b style="color: #e88404">ForesightIL</b>, a novel method that brings predictive
            reasoning to imitation learning attest time. Our approach leverages multimodal IL policies as generative
            priors over action sequences,
            combined with latent-space imaginations in a learned world model. Instead of directly executing actions, we
            sample multiple candidate trajectories, simulate their outcomes using the world model, and select the most
            promising one for execution. This setup enables goal-conditioned predictive control, allowing adaptive
            action selection toward specified targets. Furthermore, by simulating trajectories from different diffusion
            policies, each trained on single tasks, our approach enables compositional skill integration via world model
            planning. ForesightIL achieves a 29% performance gain across three simulated and two real-world robotics
            tasks, while demonstrating robust generalization to visual disturbances without any online adaptation or
            additional supervision.
          </p>
        </div>
      </div>
    </div>

    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2 class="center mb-3">Method</h2>
          <p>
            Our approach trains a diffusion policy as a generative prior over action sequences, and uses a shared latent
            world model to simulate and rank candidate trajectories. Crucially, instead of executing the policy output
            directly, we sample multiple candidate trajectories, imagine their outcomes in latent space, and select the
            most promising one for execution. This allows us to reuse generic knowledge from the training set at test
            time—without additional supervision or interaction.
          </p>

        </div>
      </div>
      <div class="col-12 center img">
        <img class="center" src="./mfiles/figs/ours_vs_gpc.png" style="width:100%"></img>
      </div>
    </div>

    <div class="container">
      <div class="row">
        <div class="col-12">
          <h2 class="center mb-3">Planning Visualizations</h2>
        </div>
      </div>
      <div class="col-12 center img">
        <img class="center" src="./mfiles/figs/planning_v2.png" style="width:100%"></img>
      </div>
    </div>

  </div>
</body>

</html>